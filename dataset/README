WORK IN PROGRESS

bindingDB_to_DTI_ready.py:
Main script of this master thesis
The current plan is for it to do the following steps
	- Take whichever version of bindingDB_all.tsv is the most current one
	- Perform a cleanup of the data (this is broadly defined, since I am currently researching which steps are resonable, but will also result in a large enough dataset for DTI problems)
	- Allow specificiations in the config file to choose how much sequence and/or compound similarity will be allowed
	
In the case tha more sources of DTI data are found the script will be changed to work with them as well if the time allows it.
Idealy multipe sources of data will be combineable




script_01:
Takes the current version of the bindingDB_all.tsv and extracts the columns of interest for DTI analysis into a separate file
Updates are paused since the following steps will be part of the evalutaion phase, and will be done on a different subset that I am working on currently
Planned update: Instead of creating a separate slimed down file it will create:
	a fasta file using the sequence and the Swissprot ID
	a SMILE file using the smile and PubCHEM CID
	an interaction file using the same IDs as the two before
	
script_02: 
To create Kiba scores you require ic50 scores and either Ki or Kd values. This script checks how many rows from bindingDB fullfill that requirement.
